# 网络协议

#### 协议三要素

1. **语法**　就是这一段内容要符合一定的规则和格式

2. **语义**　就是这一段内容要代表某种意义

3. **顺序**　就是先干啥，后干啥

   ```
   HTTP/1.1 200 OK
   Date: Tue, 27 Mar 2018 16:50:26 GMT
   Content-Type: text/html;charset=UTF-8
   Content-Language: zh-CN
   
   <!DOCTYPE html>
   <html>
   <head>
   <base href="https://pages.kaola.com/" />
   <meta charset="utf-8"/> <title> 网易考拉 3 周年主会场 </title>
   
   http
   1.状态、首部、内容符合语法　　2.符合语义　3.符合顺序
   ```


#### 浏览器输入URL经历的过程

   **URL**`https://www.kaola.com`    在浏览器中一般会通过地址簿协议**DNS(或更精准的地址簿查找协议HTTPDNS)**　会得到ip地址`106.114.138.24` ，得到目标地址之后，浏览器就开始打包它的请求，一般会全貌和**HTTP**协议，有些重要的请求需要加密传输，一般会用**HTTPS**协议。

**DNS、HTTP、HTTPS**属于应用层协议，经过应用层封装后会传给下一层**传输层**(**TCP、UDP**)两种协议，像浏览网页，购物这种一般是**TCP**。**TCP**协议会有两个端口，一个是浏览器监听的端口，一个是电商服务器的监听端口，操作系统往往通过端口判断它得到的包给哪个进程

传输层封装完毕后，公把包交给**网络层**，这里会用到**IP**协议，**IP**协议里面会有**源IP地址**：即浏览器所在机器的**IP**地址　和　**目标IP地址**：电商网站所在服务器的**IP**地址(也是通过**DNS**解析出来的**IP**地址)

如何找到目标IP地址?
既然知道了目标IP地址，那怎么知道目标IP地址是在本地还是外地呢？这里需要用到网关，就像去国外要去海关一样，操作系统启动的时候，会被DHCP协议配置IP地址，以及默认的网关IP地址192.168.1.1

操作系统在本地通过**ARP**协议把IP地址发送给网关：操作系统将IP包交给下一层，即**MAC层**,网卡把包发出去，由于这个包里有MAC地址，因此能到达网关
![](https://static001.geekbang.org/resource/image/cc/4f/cc02190ac57af7fb6c3839534f2b674f.png)



网关收到包之后，会判断下一步怎么走，网关往往是一具路由器，到某个IP地址怎么走，这个叫路由表

局域网内部可以使用本地的地址MAC进行通信，

局域网与局域网之间沟通使用**路由协议**，常用的有**OSPF**、**BGP**

到了目标局域网，通过目标IP，回复一个目标Mac，再通过mac找到目标服务器

目标服务器发现MAC地址对上后，取下MAC头，发给操作系统网络层，发现IP对上，就取下IP头，IP头里会写上一层封装的TCP协议，然后交给传输层，即TCP层，在这一层，对于收到的每一个包会有一个回复的包说明收到了，防止丢包

当网络包到达TCP层之后，TCP头中有目标端口号，通过这个端口号可以找到监听这个端口的进程。

往往一个电商网站最初接待请求的这个 Tomcat 只是个接待员，负责统筹处理这个请求，而不是所有事情自己做，这个接待员要告诉专门管理订单的进程，登记要买某个商品，买多少，要告诉管理库存的进程，库存要减少多少，要告诉支付的进程，应该付多少钱等

最后通过RPC告诉相关服务进程，



| 层级 | 协议 |
| :----- | ---- |
| 应用层       | DHCP、HTTP、HTTPS、RTMP、P2P、DNS、GTP、RPC |
| 传输层 | UDP、TCP |
| 网络层 | ICMP、IP、OSPF、BGP、IPSec、GRE |
| 链路层 | ARP、VLAN、STP |
| 物理层 | 网络跳线 |

**TCP**面向连接，能保证包能到达目地地，如果不能到达，会重新发达，直到到达

**ARP**（Address Resolution Protocol）地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议，[ARP命令](https://baike.baidu.com/item/ARP%E5%91%BD%E4%BB%A4)可用于查询本机ARP缓存中IP地址和[MAC地址](https://baike.baidu.com/item/MAC%E5%9C%B0%E5%9D%80)的对应关系

**RPC**（Remote Procedure Call）—[远程过程调用](https://baike.baidu.com/item/%E8%BF%9C%E7%A8%8B%E8%BF%87%E7%A8%8B%E8%B0%83%E7%94%A8/7854346)，它是一种通过[网络](https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C/143243)从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。[RPC协议](https://baike.baidu.com/item/RPC%E5%8D%8F%E8%AE%AE)假定某些[传输协议](https://baike.baidu.com/item/%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE/8048821)的存在，如TCP或UDP，为通信程序之间携带信息数据。在OSI[网络通信](https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/9636548)模型中，RPC跨越了[传输层](https://baike.baidu.com/item/%E4%BC%A0%E8%BE%93%E5%B1%82/4329536)和[应用层](https://baike.baidu.com/item/%E5%BA%94%E7%94%A8%E5%B1%82/4329788)。RPC使得开发包括网络[分布式](https://baike.baidu.com/item/%E5%88%86%E5%B8%83%E5%BC%8F)多程序在内的应用程序更加容易。

1、网桥，是把两个不同物理层，不同[MAC子层](https://www.baidu.com/s?wd=MAC%E5%AD%90%E5%B1%82&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)，不同速率的局域网连接在一起。比如说10MB/S与100MB/S的局域网。因为它有储存转化功能。

2、网卡是电脑的一个接收信息 转换信息 暂储信息的一个硬件。它是把接受到信息递交给上层，如（CUP）的一个接口。

3、网关(Gateway)又称网间连接器、[协议转换器](https://www.baidu.com/s?wd=%E5%8D%8F%E8%AE%AE%E8%BD%AC%E6%8D%A2%E5%99%A8&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)。网关在传输层上以实现网络互连，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。网关既可以用于广域网互连，也可以用于局域网互连。 网关是一种充当转换重任的计算机系统或设备。在使用不同的[通信协议](https://www.baidu.com/s?wd=%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE&tn=SE_PcZhidaonwhc_ngpagmjz&rsv_dl=gh_pc_zhidao)、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个翻译器。与网桥只是简单地传达信息不同，网关对收到的信息要重新打包，以适应目的系统的需求。同时，网关也可以提供过滤和安全功能。大多数网关运行在OSI 7层协议的顶层--应用层。

所以生动的表示以下，网关是邮电局,所有的信息必须通过这里的打包、封箱、寻址，才能发出去与收进来；网卡是设备，也就是邮电局邮筒，你家的信箱；而网桥是邮递员，但他只负责一个镇里面(局域网)不负责广域网。

边界网关协议（BGP）是运行于 TCP 上的一种[自治系统](https://baike.baidu.com/item/%E8%87%AA%E6%B2%BB%E7%B3%BB%E7%BB%9F/129715)的[路由协议](https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/202634)。 BGP 是唯一一个用来处理像因特网大小的网络的协议，也是唯一能够妥善处理好不相关[路由域](https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1%E5%9F%9F/1665630)间的多路连接的协议。 BGP 构建在 EGP 的经验之上。 BGP 系统的主要功能是和其他的 BGP 系统交换网络可达信息。网络可达信息包括列出的[自治系统](https://baike.baidu.com/item/%E8%87%AA%E6%B2%BB%E7%B3%BB%E7%BB%9F/129715)（AS）的信息。这些信息有效地构造了 AS 互联的拓朴图并由此清除了[路由环路](https://baike.baidu.com/item/%E8%B7%AF%E7%94%B1%E7%8E%AF%E8%B7%AF/8975272)，同时在 AS 级别上可实施策略决策。

OSPF路由协议是用于[网际协议](https://baike.baidu.com/item/%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE/4148798)（IP）网络的[链路状态路由协议](https://baike.baidu.com/item/%E9%93%BE%E8%B7%AF%E7%8A%B6%E6%80%81%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE/1219386)。该协议使用[链路状态路由算法](https://baike.baidu.com/item/%E9%93%BE%E8%B7%AF%E7%8A%B6%E6%80%81%E8%B7%AF%E7%94%B1%E7%AE%97%E6%B3%95/9708248)的[内部网关协议](https://baike.baidu.com/item/%E5%86%85%E9%83%A8%E7%BD%91%E5%85%B3%E5%8D%8F%E8%AE%AE/167192)（[IGP](https://baike.baidu.com/item/IGP/8166903)），在单一自治系统（AS）内部工作。适用于[IPv4](https://baike.baidu.com/item/IPv4/422599)的OSPFv2协议定义于RFC 2328 [1]  ，RFC 5340 [2]  定义了适用于[IPv6](https://baike.baidu.com/item/IPv6/172297)的OSPFv3。

疑问：

1.　一般情况下可以通过　`ping www.baidu.com  `来查看ip地址，但与`ping http://www.baidu.com` `ping www.baidu.com` 结果有点不一样

### 网络分层的真实含义是什么？

**复杂的程序都要分层，这是程序设计的要求。**

IP 协议里面包含目标地址和源地址。第三层里往往还会学习**路由协议**，路由就像中转站，从A到D，经过两个中转站A->B->C->D，是通过路由转发的

程序工作过程



![](https://static001.geekbang.org/resource/image/06/ea/06b355394f525c54f200d8a1af63ddea.jpg)

当一个网络包从一个网口经过的时候，先看要不要请进来，处理一把。有的网口配置了混杂模式，凡是经过的，全部请进来。
拿进来以后，交给程序处理。用**process_layer2(buffer)** 摘掉二层的头，根据头里面的内容做相应操作
如果这个包的MAC地址与自己的的相符，那就是发给自己的，调用**process_layer3(buffer)**,摘掉三层的头，看相应操作，是发给自己的，还是希望自己转发出去（根据IP地址是不是自己的来判断）
如果这个地址是TCP的，那么会调用**process_tcp(buffer)**，这时看Buffer里面四层的头，看是不个发起还是一个应答(需要做回复操作)，又或是一个正常的数据包(需要交给上层)，然后做相应的操作，

交给上层时，在四层里有端口号，根据端口号找到监听这个端口号的应用，然后交给这个应用就可以了



发起HTTP请求时，

先调用**send_tcp(buffer)**，Buffer里面就是http请求的内容，这个函数加一个tcp的头，记录下端口号
然后调用**send_layer3(buffer)**,Buffer里边已经有HTPP的头和内容了，以及tcp的头，在这个函数里加一个IP的头，记录下源IP的地址和目标IP的地址
再调用**send_layer2(buffer)**,在这个函数中加MAC头，记录下源MAC地址，得到的就是MAC地址和目标的MAC地址，不过，还要看当前知不知道，知道就直接加上，不知道，需要通过一定的协议处理过程，找到MAC地址，填一下不能空着
此时，只要buffer里面的内容完整，就可以从网口发出去了

TCP三次握手的时候，TCP每发送一个消息，都会带着IP层和MAC层，因为TCP每发一个消息，IP层和MAC层的所有机制都要运行一遍。

**只要是在网络上跑的包，都是完整的，可以有下层没有上层，绝对不可能有上层没下层**
**对TCP协议来说，三次握手也好，重试也好，只要想发出去的包，就要有IP层和MAC层，不然是发不出去的**

知道IP地址，直接给他发消息时，如果没有MAC地址是发不出去的

二层设备就是只把MAC头摘下来，看是丢弃、转发、还是自己留着
三层设备就是在摘完MAC后，把IP头摘下来，看是丢弃、转发、还是自己留着

### Ifconfig  

在windows上是**ipconfig** ，linux上是**ifconfig**
ifconfig(linux没有请安装net-tools,mac下自带)
ip addr(linux没有请安装iproute2，mac下请安装iproute2mac`brew install iproute2mac`)

```
 ~  ip addr
lo0: flags=8049<UP,LOOPBACK,RUNNING,MULTICAST> mtu 16384
	inet 127.0.0.1/8 lo0
	inet6 ::1/128
	inet6 fe80::1/64 scopeid 0x1
en1: flags=8863<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST> mtu 1500
	ether 6c:96:cf:f2:b8:50
	inet6 fe80::1cc8:eb8c:e652:e45f/64 secured scopeid 0x6
	inet 172.16.100.8/24 brd 172.16.100.255 en1
awdl0: flags=8943<UP,BROADCAST,RUNNING,PROMISC,SIMPLEX,MULTICAST> mtu 1484
	ether 66:30:19:0c:b2:b5
	inet6 fe80::6430:19ff:fe0c:b2b5/64 scopeid 0x8
utun0: flags=8051<UP,POINTOPOINT,RUNNING,MULTICAST> mtu 2000
	inet6 fe80::d72e:e341:f17b:baff/64 scopeid 0xc
```

**IP 地址是一个网卡在网络世界的通讯地址，相当于我们现实世界的门牌号**
如上`172.16.100.8`就是本机的ip地址，被分为4个部分，第个部分8bit,所以ip地址32位
不够用，因此就有了IPv6 如上图`fe80::1cc8:eb8c:e652:e45f/64`,这个有**128位**看起来够用了
**IPv6格式为**X:X:X:X:X:X:X:X，其中每个X表示地址中的16b，以十六进制表示
在某些情况下，一个IPv6地址中间可能包含很长的一段0，可以把连续的一段0压缩为`::`。但为保证地址解析的唯一性，地址中`::`只能出现一次

32位IP被分成了5类
![](https://static001.geekbang.org/resource/image/0b/9e/0b32d6e35ff0bbc5d46cfb87f6669d9e.jpg)

A、B、C三类地址主要分为两部分，1.网络号　2.主机号
![](https://static001.geekbang.org/resource/image/e9/be/e9c59a4b2f0b804356759b10440ea7be.jpg)

**无类型域间选路CIDR**
打破原来的分类做法，将32位IP地址一分为二，前面是**网络号**后面是**主机号**
`172.16.100.8/24`  斜杠后有个24，表明前24位是**网络号**，后面8位是**主机号**
**广播地址**　在使用TCP/IP 协议的网络中，主机标识段host ID 为全1 的IP 地址为广播地址，
如　**172.16.100.255(255即为2进制的11111111)**　如果发送这个地址，所有172.16.100网络里面的机器都可以收到
**子网掩码**
对于A类地址来说，默认的子网掩码是255.0.0.0；
对于B类地址来说默认的子网掩码是255.255.0.0；
对于C类地址来说默认的子网掩码是255.255.255.0。

**网络号**
将子网掩码和 IP 地址按位计算 AND，就可得到网络号?

**公有 IP 地址和私有 IP 地址**
![](https://static001.geekbang.org/resource/image/90/93/901778433f2d6e27b916e9e53c232d93.jpg)

一般都是私有 IP 地址段。因为这些地址允许组织内部的 IT人员自己管理、分配，而且可以重复
公有IP地址有个组织统一分配，需要购买。类似百度这样的网站给所有人用的，如果只给自己人用，私有IP地址就可以做到
192.168.0.x 常用的私有IP地址，家里有WIFI，对应就有一个IP地址。家里的上网设备一般不会超过256个，故/24基本够用，当然也有/16的**CIDR**
不需要转为二进制，可以明显看出`192.168.0`是网络号，后面是主机号
而第一个地址`192.168.0.1`一般是私有网络账号的出口地址，如家里Wi-Fi路由器的地址就是`192.168.0.1`而`192.168.0.255`就是广播地址，一旦发送这个地址，整个`192.168.0`网络里面的所有机器都能收到

**其他情况**
如`16.158.165.91/22`
`165` => `10100101‬` 除了`16.158`加起来的16位还差6位
所以　`16.158.<10100>`是网络号，　`<01>.91`是机器号
第一个地址是`16.158.<10100><00>.1` 所以是`16.158.164.1`
子网掩码`16.158.<111111>`<00>.0即`255.255.252.0`
广播地址`16.158.<10100><11>.255`,即`16.158.167.255`
**组播地址**属于某个组的机器都能收到
**IP**地址后面有个scope, 对于global 表明可以对外，对于**lo**(**loopback**)来讲，是host,表明仅供本机相互通信

#### MAC地址

如`c:96:cf:f2:b8:50`是一个网卡的物理地址，用十六进制，6个byte表示
MAC地址号称全局唯一，不会有两个网卡有相同的MAC地址，自网卡生成出来就带着这个地址。
**一个网络包需要入一个地方传到另一个地方，除了需要确定的地址，还需要定位功能**，而具有门牌号属性的IP地址才带有定位功能。
**MAC地址更像一个身份证，是一个唯一标识**
MAC地址有一定的定位功能，不过范围非常有限，局限在一个子网里面，跨子网MAC地址就不行了，需要用IP地址
**网络设备的状态标识** **net_device flags**
`<UP,BROADCAST,SMART,RUNNING,SIMPLEX,MULTICAST>`
UP表示网卡处于启动状态
BROADCAST:有广播地址，可以发送广播包
MULTICAST：网卡可以发送多播包
LOWER_UP:L1是启动的，即网线插头
MTU1500:最大传输单元MTU为1500，这是以太网默认值

**qdisc(queueing discipline)** 排队规则，内核如果需要通过某个网络接品发送数据包，需要按照为这个接吕配置的**qdisc(排除规则)**所数据包加入队列
最简单的qdisc是pfifo，不对数据包做任何处理，先入先出方式通过队列
pfifo_fast　包括三个波段(band),在每个波段里使用先进先出规则
三个波段(band)优先级也不同，band 0最高，band 2最低，如果band 0里面有数据包，系统就不会处理band 1里面的数据包。
数据包是按照服务类型**（Type of Service,TOS)**，被分配到三个波段(band)
TOS是IP头里面的一个字段，代表了当前的包是最高优先级的，还是低优先级的

### IP是怎么来的，又是怎么没的？

#### 如何配置IP地址

todo:

配置一个和谁都不搭边的地址，会导致包发不出去，如旁边都是192.168.1.x,自己配置一个16.158.23.6，这　样发不出去
**只要在网络上的包，都是完整的，可以有下层没上层，但不能有上层没下层**
`16.158.23.6`自己的mac地址自己知道，但目标MAC地址呢？Linux首先会判断要去的地址是否和我一个网段，只有一个网段的才会发送ARP请求，获取MAC地址
**Linux默认逻辑是，如果这是一个跨网段的调用，它不会直接把包发送到网络上，而是企图将包发送到网关**
如果配置了网关的话，会获取网关的MAC地址，然后将包发送出去。对`192.168.1.6`这台机器来讲，虽然路过它家门口的包的目标IP是它，但MAC地址不是它的，所以不会把包收进去
如果没有配置风头，包根本就发不出去
如果将网关配置为`192.168.1.6`呢？linux不会配置成功的，网关得和当前网络至少是一个网段的，`16.158.23.6`的网关不可能是`192.168.1.6`
当手动配置一台机器的网络IP时，需要问网络管理员，分配正确的IP地址，
**不同系统的配置文件格式不同，但是无非是CIDR、子网掩码、广播地址和网关地址**

**动态主机配置协议(DHCP)**

只需要配置一段共享的IP地址，每一台新接入的机器都通过DHCP协议，来共享这个IP地址的申请，然后自动配置，等人走了，还回去，其他机器可以使用

**如果是数据中心的服务器，IP一旦配置好，基本不会变，相当于买房装修，**
**DHCP相当于租房，不用装修，帮你配置好，暂时用一下，用完退租就好了**

新来的机器通过0.0.0发送一个广播包，目的IP为255.255.255.255.广播包封装了UDP,UDP封装了BOOTP，其实DHCP是BOOTP的增强版，如果抓包的话，可能看到的还是BOOTP协议
新人，我是新来的，我的MAC地址是这个，求一个IP地址
![](https://static001.geekbang.org/resource/image/39/1f/395b304f49559034af34c882bd86f11f.jpg)

如果配置了**DHCP Server**，就相当于这些IP的管理员，来新人就会知道，给新一个IP地址称为**DHCP Offer**，
同时保留它提供的IP地址，从而不会为其他DHCP客户分配些IP地址
![](https://static001.geekbang.org/resource/image/54/86/54ffefbe4f493f0f4a39f45504bd5086.jpg)

DHCP Server仍然使用广播地址作为目的地址，因为些时新人还没有IP地址，DHCP Server会回复可用IP及子网掩码，网关，IP地址租用期，如果有多个DHCP Server，新人会收到多个DHCP Offer，新人一般会选择最先到达的那一个，并向网络发送一个DHCP Request广播数据包，包中包含MAC地址，接受租约的IP地址，提供此租约的DHCP服务器地址，并告知所有DHCP Server它所有接受哪一台服务器提供的IP地址，告知其他DHCP服务器撤销他们提供的IP地址，以便给下一个人使用
![](https://static001.geekbang.org/resource/image/e1/24/e1e45ba0d86d2774ec80a1d86f87b724.jpg)

由于还没有得到DCHP Server的最终确认，客户端仍然使用0.0.0.0为IP地址，255.255.255.255为目标地址进行广播，在BOOTP里面接受某个DHCP Server分配的IP.
当DHCP　Server接收客户端DHCP Request之后，会广播返回给客户一个DHCP ACK消息包，表明已经接受客户机的选择，并将这一IP地址的合法租用信息和其他配置信息都放入该广播包，发给客户机。
![](https://static001.geekbang.org/resource/image/7d/0e/7da571c18b974582a9cfe4718c5dea0e.jpg)

最终需要广播一下，让大家都知道
**IP地址的收回和续租**

客户机在租期过去50％时，会向其提供DHCP Server发送DHCP Request消息包。客户机在接收到该服务器回应的DHCP ACK消息包时，会根据包中所提供的新租期及其他更新的TCP/IP参数，更新自己的配置。

网络管理员不仅可以自动分配IP地址，还能帮你自动安装操作系统

**预启动执行环境(PXE)**　了解即可

![](https://static001.geekbang.org/resource/image/6e/a4/6e69007db3fc68ff6da8496266abf6a4.jpg)

### 物理层到MAC层

**第一层物理层**
电脑连电脑，一根网络，两个头，水晶头要做交叉线 使用**1－3、2－6交叉接法**
水晶头的第1、2和3、6分别起着收、发信号作用，将一端的1号线和3号线，2号和6号线互换一下位置，就能实现一　端发送信号，另一端能收到
还需要配置这两台电脑IP地址，子网掩码和默认网关。可以是`192.168.0.1/24`和 `192.168.0.2/24`
这样就构成了一个最小的**局域网**，即**LAN**

三台电脑　　交换机、Hub集线器(N年前，将自己收到的每一个字节都复制到其它端口)

**第二层数据链路层**

MAC全称Medium Access Control，媒体访问控制。控制在往媒体上改善数据时，谁先发谁后发的问题。防止发生混乱。
多路访问

1. **信道划分**　分多个车道，每个车一个车道，你走你的，我走我的。
2. **轮流协议**  今天单号出行，明天又号出行，轮着来
3. **随机接入协议**　有事先出门，发现特别堵，就回去，错过高峰再出　以太网用得就是这个方式

链路层地址，但因为第二层主要解决媒体接入控制的问题，所以常被称为MAC地址

对于以太网，第二层的最开始，就是目标的MAC地址及源MAC地址

![](https://static001.geekbang.org/resource/image/ce/ed/cef93d665ca863fef40f7f854d5d33ed.jpg)

接下来是**类型**，大部分的类型是IP数据包，然后IP里面包含了TCP、UDP，以及HTTP等，这些都是里层封装的事情

**局域网**
交换机　
交换机怎么知道每个口的电脑的MAC地址？　这需要交换学习机会
一台MAC1电脑交一个包发送给另一台MAC2电脑，当这个包到达交换机时，一开始交换机也不知道MAC2的电脑在哪个口，所以，他公将包转发除来的那个口外的其他所有口，**这时**，交换机会记信MAC1是来自一个明确的口，以后有包的目的的MAC1的，直接发送到这个口就可以了。

等过了一段时间，交换机就有了整个网络的一个结构，基本上不用广播了，全部可以准备转发。当然，每个机器的IP地址会变，所在的口也会变，因此交换机上的学习结果，即**转发表**，有过期时间



### 交换机与VLAN

#### 拓扑结构是怎么形成的？

如办公室需要多台交换机，把交换机连接起来，就形成一个稍微复杂的**拓扑结构**

1. 两台交换机，连接三个局域网，每个局域网有多台机器，
   ![](https://static001.geekbang.org/resource/image/7a/73/7a40046c5a2c7f7cd3c95b54488b9773.jpg)

如果机器1只知道机器4的IP地址，当想访问机器4的时候，必须知道机器4的MAC地址
于是机器1发起广播，只有机器4主动响应，这是找我的，于是一个ARP请求就完成了
在上面的过程中，交换机A和交换机B能学习到这样的结果，机器1在左边的网口。

当机器2访问机器1的时候，机器2不知道机器1的MAC地址，会发ARP请求，这个广播会到达机器1，和交换机A,
这时候交换机A已经知道机器1不可能在右边的网口，所以这个广播信息不会广播到局域网二和局域网三

当机器3访问机器1的时候，交换机B不会将消息广播到局域网三



#### 如何解决常见的环路问题

![](https://static001.geekbang.org/resource/image/c8/d2/c829b28978c3d9686680e4b62fdf53d2.jpg)



机器1不知道机器2的MAC地址，故机器1发ARP广播，广播到达机器2之后，会所MAC地址返回，看起来正常
但交换机A、B都能收到广播，交换机A不知道机器2在哪，会把广播消息发到局域网二，在局域网二广播时，交换机右边的网口能收到广播消息，然后交换机B会把广播消息发送到局域网一，然后到A，之后无限循环。

交换学习：机器1广播到达交换机A和B时，机器1在局域网一，但当交换机A将包广播到局域网二之后，交换机B会认为机器1在右边的网口，清理之前学习记录，同理交换机A，右边的网口也能收到交换机B转发的广播包



#### STP协议中一些概念

**最小生成树**，有环的常称为**图**，在计算机网络中生成树的算法叫**STP(Spanning Three Protocol)**
![](https://static001.geekbang.org/resource/image/5d/ba/5d3ba40babdacc735f617cc2356fefba.jpg)

**Root Bridge**根交换机
**Designated Bridge**　指定交换机
**Bridge Protocol Data Units(BPDU)** 网桥协议数据单元
**Priority Vector** 优先级向量

**todo:**stp将有环路的图变成没有环路的树来解决环路问题，



交换机数目多面临隔离问题

物理隔离

虚拟隔离，VLAN　虚拟局域网



### ICMP 与 Ping

**ICMP(Internet Control  Message Protocol)互联网控制报文协议**

![](https://static001.geekbang.org/resource/image/23/ff/23aecf653d60dd94b7c5c6dc21ca21ff.jpg)

ICMP封装在IP包里面
ICMP报文有很多类型，不同类型有不同的代码，是常用的类型是主动请求为8，主动应答为0
ping是查询报文，是一种主动请求，并且获得主动应答的ICMP协议，所以ping发的包是符合ICMP协议格式的，只不过它在后面增加了自己的格式
对ping的主动请求，进行网络抓包，称为　**ICMP ECHO REQUEST**,主动请求的回复，称为**ICMP ECHO REPLY**比起原生ICMP　多了两个字段，一个是**标识符**，一个是**序号**

差错报文类型
**终点不可达为3，**
**源抑制为4，**　让源站放慢发送速度
**超时为11，**
**重定向为5**

ping：查询报文类型的使用
![](https://static001.geekbang.org/resource/image/e5/fc/e5270427819fc51c88e81a5c1cc4b8fc.jpg)

假定主机A的IP地址192.168.1.1　主机B的IP地址192.168.1.2，在A上`ping 192.168.1.2` 会发生什么？
执行ping命令时，源主机会先构建一个ICMP请求，ICMP数据包内包含多个字段，最重要的是两个，一个**类型字段**,对于请求数据包而言该字段为8，另一个是**顺序号**，主要用来区分连续ping的时候，发出的多个数据包，每发出一个请求数据包，顺序号自动加1，为了能够计算往返时间，它会在报文的数据部分插入发送时间。

#### Traceroute：差错报文类型的使用

Traceroute：差错报文类型的使用 那其他的类型呢？

是不是只有真正遇到错误的时候，才能收到呢？那也不是，有一个程序 Traceroute，是个“大骗子”。它会使用 ICMP 的规则，故意制造一些能够产生错误的场景。 所以，Traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。Traceroute 的参数指向某个目的 IP 地址，它会发送一个 UDP 的数据包。将 TTL 设置成 1，也就是说一旦遇到一个路由器或者一个关卡，就表示它“牺牲”了。 如果中间的路由器不止一个，当然碰到第一个就“牺牲”。于是，返回一个 ICMP 包，也就是网络差错包，类型是时间超时。那大军前行就带一顿饭，试一试走多远会被饿死，然后找个哨探回来报告，那我就知道大军只带一顿饭能走多远了。



### 出网关

路由器，网卡，网关

MAC头和IP头



如果离开本局域网，就需要经过网关，网关是路由器的一个网口； 
路由器是一个三层设备，里面有如何寻找下一跳的规则；
经过路由器之后 MAC 头要变，如果 IP 不变，相当于不换护照的欧洲旅游，如果 IP 变，相当于换护照的玄奘西行。



### 路由协议

**路由表**

每一条规则至少包含这三项信息。 

目的网络：这个包想去哪儿？ 
出口设备：将包从哪个口扔出去？ 
下一跳网关：下一个路由器的地址。



**如何配置策略路由？**



1. 距离矢量路由算法 第一大类的算法称为距离矢量路由（distance vector routing）。它是基于 Bellman-Ford 算法的。

2. 链路状态路由算法 第二大类算法是链路状态路由（link state routing），基于 Dijkstra 算法。

动态路由协议 

1. 基于链路状态路由算法的 OSPF OSPF（Open Shortest Path First，开放式最短路径优先）就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议（Interior Gateway Protocol，简称IGP）。
2. 2. 基于距离矢量路由算法的 BGP 但是外网的路由协议，也即国家之间的，又有所不同。我们称为外网路由协议（Border Gateway Protocol，简称BGP）。

路由分静态路由和动态路由，静态路由可以配置复杂的策略路由，控制转发策略； 动态路由主流算法有两种，距离矢量算法和链路状态算法。基于两种算法产生两种协议，BGP 协议和 OSPF 协议。





### UDP协议

#### TCP 和 UDP 有哪些区别？

大部分人会回答，TCP 是面向连接的，UDP 是面向无连接的。 

什么叫面向连接，什么叫无连接呢？在互通之前，面向连接的协议会先建立连接。

例如，TCP 会三次握手，而 UDP 不会。为什么要建立连接呢？你 TCP 三次握手，我 UDP 也可以发三个包玩玩，有什么区别吗？

**所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性**

 例如，TCP 提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。我们都知道 IP 包是没有任何可靠性保证的，一旦发出去，就像西天取经，走丢了、被妖怪吃了，都只能随它去。但是 TCP 号称能做到那个连接维护的程序做的事情，这个下两节我会详细描述。而UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达。 再如，TCP 是面向字节流的。发送的时候发的是一个流，没头没尾。IP 包可不是一个流，而是一个个的 IP 包。之所以变成了流，这也是 TCP 自己的状态维护做的事情。

而UDP 继承了 IP 的特性，基于数据报的，一个一个地发，一个一个地收。 还有TCP 是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP 就不会，应用让我发，我就发，管它洪水滔天。 因而TCP 其实是一个有状态服务，通俗地讲就是有脑子的，里面精确地记着发送了没有，接收到没有，发送到哪个了，应该接收哪个了，错一点儿都不行。而 UDP 则是无状态服务。 通俗地说是没脑子的，天真无邪的，发出去就发出去了。 

我们可以这样比喻，如果 MAC 层定义了本地局域网的传输行为，IP 层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因：网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段。我们笼统地称为包。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。基于这个基因，生下来的孩子 UDP 完全继承了这些特性，几乎没有自己的思想。 UDP 包头是什么样的？ 我们来看一下 UDP 包头。 前面章节我已经讲过包的传输过程，这里不再赘述。当我发送的 UDP 包到达目标机器后，发现 MAC 地址匹配，于是就取下来，将剩下的包传给处理 IP 层的代码。把 IP 头取下来，发现目标 IP 匹配，接下来呢？这里面的数据包是给谁呢？ 发送的时候，我知道我发的是一个 UDP 的包，收到的那台机器咋知道的呢？所以在 IP 头里面有个 8 位协议，这里会存放，数据里面到底是 TCP 还是 UDP，当然这里是 UDP。于是，如果我们知道 UDP 头的格式，就能从数据里面，将它解析出来。解析出来以后呢？数据给谁处理呢？ 处理完传输层的事情，内核的事情基本就干完了，里面的数据应该交给应用程序自己去处理，可是一台机器上跑着这么多的应用程序，应该给谁呢？ 无论应用程序写的使用 TCP 传数据，还是 UDP 传数据，都要监听一个端口。正是这个端口，用来区分应用程序，要不说端口不能冲突呢。两个应用监听一个端口，到时候包给谁呀？所以，按理说，无论是 TCP 还是 UDP 包头里面应该有端口号，根据端口号，将数据交给相应的应用程序。 ﻿﻿ 当我们看到 UDP 包头的时候，发现的确有端口号，有源端口号和目标端口号。因为是两端通信嘛，这很好理解。但是你还会发现，UDP 除了端口号，再没有其他的了。和下两节要讲的 TCP 头比起来，这个简直简单得一塌糊涂啊！ 

UDP 的三大特点 UDP 就像小孩子一样，有以下这些特点：

 **第一，沟通简单**，不需要一肚子花花肠子（大量的数据结构、处理逻辑、包头字段）。前提是它相信网络世界是美好的，秉承性善论，相信网络通路默认就是很容易送达的，不容易被丢弃的。 

第二，轻信他人。它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也可以传给任何人数据，甚至可以同时传给多个人数据。 

第三，愣头青，做事不懂权变。不知道什么时候该坚持，什么时候该退让。它不会根据网络的情况进行发包的拥塞控制，无论网络丢包丢成啥样了，它该怎么发还怎么发。

 UDP 的三大使用场景 基于 UDP 这种“小孩子”的特点，我们可以考虑在以下的场景中使用。 

第一，需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。这很好理解，就像如果你是领导，你会让你们组刚毕业的小朋友去做一些没有那么难的项目，打一些没有那么难的客户，或者做一些失败了也能忍受的实验性项目。 我们在第四节讲的 DHCP 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 又没事，过一会儿还有机会。我们讲过 PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。在还没有操作系统的时候，客户端拥有的资源很少，不适合维护一个复杂的状态机，而是因为是内网，一般也没啥问题。

 第二，不需要一对一沟通，建立连接，而是可以广播的应用。咱们小时候人都很简单，大家在班级里面，谁成绩好，谁写作好，应该表扬谁惩罚谁，谁得几个小红花都是当着全班的面讲的，公平公正公开。长大了人心复杂了，薪水、奖金要背靠背，和员工一对一沟通。 UDP 的不面向连接的功能，可以使得可以承载广播或者多播的协议。DHCP 就是一种广播的形式，就是基于 UDP 协议的，而广播包的格式前面说过了。 对于多播，我们在讲 IP 地址的时候，讲过一个 D 类地址，也即组播地址，使用这个地址，可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址的时候，需要发送 IGMP 包，所在网络的路由器就能收到这个包，知道有个机器上有个进程在监听这个组播地址。当路由器收到这个组播地址的时候，会将包转发给这台机器，这样就实现了跨路由器的组播。 在后面云中网络部分，有一个协议 VXLAN，也是需要用到组播，也是基于 UDP 协议的。 

第三，需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。记得曾国藩建立湘军的时候，专门招出生牛犊不怕虎的新兵，而不用那些“老油条”的八旗兵，就是因为八旗兵经历的事情多，遇到敌军不敢舍死忘生。 同理，UDP 简单、处理速度快，不像 TCP 那样，操这么多的心，各种重传啊，保证顺序啊，前面的不收到，后面的没法处理啊。不然等这些事情做完了，时延早就上去了。而 TCP 在网络不好出现丢包的时候，拥塞控制策略会主动的退缩，降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。 当前很多应用都是要求低时延的，它们可不想用 TCP 如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证。例如，如果应用自己觉得，有的包丢了就丢了，没必要重传了，就可以算了，有的比较重要，则应用自己重传，而不依赖于 TCP。有的前面的包没到，后面的包到了，那就先给客户展示后面的嘛，干嘛非得等到齐了呢？如果网络不好，丢了包，那不能退缩啊，要尽快传啊，速度不能降下来啊，要挤占带宽，抢在客户失去耐心之前到达。 由于 UDP 十分简单，基本啥都没做，也就给了应用“城会玩”的机会。就像在和平年代，每个人应该有独立的思考和行为，应该可靠并且礼让；但是如果在战争年代，往往不太需要过于独立的思考，而需要士兵简单服从命令就可以了。 曾国藩说哪支部队需要诱敌牺牲，也就牺牲了，相当于包丢了就丢了。两军狭路相逢的时候，曾国藩说上，没有带宽也要上，这才给了曾国藩运筹帷幄，城会玩的机会。同理如果你实现的应用需要有自己的连接策略，可靠保证，时延要求，使用 UDP，然后再应用层实现这些是再好不过了。



基于UDP的例子

基于 UDP 的“城会玩”的五个例子 我列举几种“城会玩”的例子。

 “城会玩”一：网页或者 APP 的访问 原来访问网页和手机 APP 都是基于 HTTP 协议的。HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP 可能还会断了重连，也是很耗时的。而且目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。 而QUIC（全称Quick UDP Internet Connections，快速 UDP 互联网连接）是 Google 提出的一种基于 UDP 改进的通信协议，其目的是降低网络通信的延迟，提供更好的用户互动体验。 QUIC 在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。这一节主要是讲 UDP，QUIC 我们放到应用层去讲。

 “城会玩”二：流媒体的协议 现在直播比较火，直播协议多使用 RTMP，这个协议我们后面的章节也会讲，而这个 RTMP 协议也是基于 TCP 的。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认，如果前一个收不到，下一个就算包已经收到了，在缓存里面，也需要等着。对于直播来讲，这显然是不合适的，因为老的视频帧丢了其实也就丢了，就算再传过来用户也不在意了，他们要看新的了，如果老是没来就等着，卡顿了，新的也看不了，那就会丢失客户，所以直播，实时性比较比较重要，宁可丢包，也不要卡顿的。 另外，对于丢包，其实对于视频播放来讲，有的包可以丢，有的包不能丢，因为视频的连续帧里面，有的帧重要，有的不重要，如果必须要丢包，隔几个帧丢一个，其实看视频的人不会感知，但是如果连续丢帧，就会感知了，因而在网络不好的情况下，应用希望选择性的丢帧。 还有就是当网络不好的时候，TCP 协议会主动降低发送速度，这对本来当时就卡的看视频来讲是要命的，应该应用层马上重传，而不是主动让步。因而，很多直播应用，都基于 UDP 实现了自己的视频传输协议。 

“城会玩”三：实时游戏 游戏有一个特点，就是实时性比较高。快一秒你干掉别人，慢一秒你被别人爆头，所以很多职业玩家会买非常专业的鼠标和键盘，争分夺秒。 因而，实时游戏中客户端和服务端要建立长连接，来保证实时传输。但是游戏玩家很多，服务器却不多。由于维护 TCP 连接需要在内核维护一些数据结构，因而一台机器能够支撑的 TCP 连接数目是有限的，然后 UDP 由于是没有连接的，在异步 IO 机制引入之前，常常是应对海量客户端连接的策略。 另外还是 TCP 的强顺序问题，对战的游戏，对网络的要求很简单，玩家通过客户端发送给服务器鼠标和键盘行走的位置，服务器会处理每个用户发送过来的所有场景，处理完再返回给客户端，客户端解析响应，渲染最新的场景展示给玩家。 如果出现一个数据包丢失，所有事情都需要停下来等待这个数据包重发。客户端会出现等待接收数据，然而玩家并不关心过期的数据，激战中卡 1 秒，等能动了都已经死了。 游戏对实时要求较为严格的情况下，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。

 “城会玩”四：IoT 物联网 一方面，物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护 TCP 协议代价太大；另一方面，物联网对实时性要求也很高，而 TCP 还是因为上面的那些原因导致时延大。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的。

 “城会玩”五：移动通信领域 在 4G 网络里，移动流量上网的数据面对的协议 GTP-U 是基于 UDP 的。因为移动网络协议比较复杂，而 GTP 协议本身就包含复杂的手机上线下线的通信协议。如果基于 TCP，TCP 的机制就显得非常多余，这部分协议我会在后面的章节单独讲解。

### TCP协议



TCP 包头格式

TCP 的三次握手
![](https://static001.geekbang.org/resource/image/66/a2/666d7d20aa907d8317af3770411f5aa2.jpg)

TCP 四次挥手

![](https://static001.geekbang.org/resource/image/1f/11/1f6a5e17b34f00d28722428b7b8ccb11.jpg)

TCP 状态机

![](https://static001.geekbang.org/resource/image/da/ab/dab9f6ee2908b05ed6f15f3e21be88ab.jpg)

TCP 包头很复杂，但是主要关注五个问题，顺序问题，丢包问题，连接维护，流量控制，拥塞控制； 连接的建立是经过三次握手，断开的时候四次挥手，一定要掌握的我画的那个状态图。



如何实现一个靠谱的协议？

 TCP 协议使用的也是同样的模式。为了保证顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答（cumulative acknowledgment）。 为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。

发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分。 

第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。 

第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。

 第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。 

第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。 

这里面为什么要区分第三部分和第四部分呢？

没交代的，一下子全交代了不就完了吗？ 这就是我们上一节提到的十个词口诀里的“流量控制，把握分寸”。作为项目管理人员，你应该根据以往的工作情况和这个员工反馈的能力、抗压力等，先在心中估测一下，这个人一天能做多少工作。如果工作布置少了，就会不饱和；如果工作布置多了，他就会做不完；如果你使劲逼迫，人家可能就要辞职了。 

顺序问题与丢包问题

流量控制问题

顺序问题、丢包问题、流量控制都是通过滑动窗口来解决的，这其实就相当于你领导和你的工作备忘录，布置过的工作要有编号，干完了有反馈，活不能派太多，也不能太少； 拥塞控制是通过拥塞窗口来解决的，相当于往管道里面倒水，快了容易溢出，慢了浪费带宽，要摸着石头过河，找到最优值。 





### Socket

![](https://static001.geekbang.org/resource/image/77/92/77d5eeb659d5347874bda5e8f711f692.jpg)

![](https://static001.geekbang.org/resource/image/60/8c/602d09290bd4f9e0183f530e9653348c.jpg)

这个图的内容就是基于 UDP 协议的 Socket 程序函数调用过程。
![](https://static001.geekbang.org/resource/image/77/ef/778687d1a02ffc0c24078c33be2ac1ef.jpg)

服务器如何接更多的项目？

方式一：将项目外包给其他公司（多进程方式）

方式二：将项目转包给独立的项目组（多线程方式）

方式三：一个项目组支撑多个项目（IO 多路复用，一个线程维护多个 Socket）

方式四：一个项目组支撑多个项目（IO 多路复用，从“派人盯着”到“有事通知”）







### HTTP协议

HTTP 请求的准备
 浏览器会将` www.163.com `这个域名发送给 DNS 服务器，让它解析为 IP 地址。有关 DNS 的过程，其实非常复杂，这个在后面专门介绍 DNS 的时候，我会详细描述，这里我们先不管，反正它会被解析成为 IP 地址。

那接下来是发送 HTTP 请求吗？ 不是的，HTTP 是基于 TCP 协议的，当然是要先建立 TCP 连接了，怎么建立呢？还记得第 11 节讲过的三次握手吗？ 目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，默认是开启了 Keep-Alive 的，这样建立的 TCP 连接，就可以在多次请求中复用。 学习了 TCP 之后，你应该知道，TCP 的三次握手和四次挥手，还是挺费劲的。如果好不容易建立了连接，然后就做了一点儿事情就结束了，有点儿浪费人力和物力。



HTTP 请求的构建
 建立了连接以后，浏览器就要发送 HTTP 的请求。

![](https://static001.geekbang.org/resource/image/10/74/10ff27d1032bf32393195f23ef2f9874.jpg)

第一部分：请求行 在请求行中，URL 就是` http://www.163.com `，版本为 HTTP 1.1。

这里要说一下的，就是方法。方法有几种类型。 对于访问网页来讲，最常用的类型就是GET。顾名思义，GET 就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如说返回一个 JSON 字符串，到底要返回什么，是由服务器端的实现决定的。 例如，在云计算中，如果我们的服务器端要提供一个基于 HTTP 协议的 API，获取所有云主机的列表，这就会使用 GET 方法得到，返回的可能是一个 JSON 字符串。字符串里面是一个列表，列表里面是一项的云主机的信息。 另外一种类型叫做POST。它需要主动告诉服务端一些信息，而非获取。要告诉服务端什么呢？一般会放在正文里面。正文可以有各种各样的格式。常见的格式也是 JSON。 例如，我们下一节要讲的支付场景，客户端就需要把“我是谁？我要支付多少？我要买啥？”告诉服务器，这就需要通过 POST 方法。 再如，在云计算里，如果我们的服务器端，要提供一个基于 HTTP 协议的创建云主机的 API，也会用到 POST 方法。这个时候往往需要将“我要创建多大的云主机？多少 CPU 多少内存？多大硬盘？”这些信息放在 JSON 字符串里面，通过 POST 的方法告诉服务器端。 还有一种类型叫PUT，就是向指定资源位置上传最新内容。但是，HTTP 的服务器往往是不允许上传文件的，所以 PUT 和 POST 就都变成了要传给服务器东西的方法。 在实际使用过程中，这两者还会有稍许的区别。POST 往往是用来创建一个资源的，而 PUT 往往是用来修改一个资源的。 例如，云主机已经创建好了，我想对这个云主机打一个标签，说明这个云主机是生产环境的，另外一个云主机是测试环境的。那怎么修改这个标签呢？往往就是用 PUT 方法。 再有一种常见的就是DELETE。这个顾名思义就是用来删除资源的。例如，我们要删除一个云主机，就会调用 DELETE 方法。

第二部分：首部字段 请求行下面就是我们的首部字段。首部是 key value，通过冒号分隔。这里面，往往保存了一些非常重要的字段。 例如，Accept-Charset，表示客户端可以接受的字符集。防止传过来的是另外的字符集，从而导致出现乱码。 再如，Content-Type是指正文的格式。

例如，我们进行 POST 的请求，如果正文是 JSON，那么我们就应该将这个值设置为 JSON。 这里需要重点说一下的就是缓存。为啥要使用缓存呢？那是因为一个非常大的页面有很多东西。 例如，我浏览一个商品的详情，里面有这个商品的价格、库存、展示图片、使用手册等等。商品的展示图片会保持较长时间不变，而库存会根据用户购买的情况经常改变。如果图片非常大，而库存数非常小，如果我们每次要更新数据的时候都要刷新整个页面，对于服务器的压力就会很大。 对于这种高并发场景下的系统，在真正的业务逻辑之前，都需要有个接入层，将这些静态资源的请求拦在最外面。 这个架构的图就像这样。 其中 DNS、CDN 我在后面的章节会讲。和这一节关系比较大的就是 Nginx 这一层，它如何处理 HTTP 协议呢？对于静态资源，有 Vanish 缓存层。当缓存过期的时候，才会访问真正的 Tomcat 应用集群。 在 HTTP 头里面，Cache-control是用来控制缓存的。当客户端发送的请求中包含 max-age 指令时，如果判定缓存层中，资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定 max-age 值为 0，那么缓存层通常需要将请求转发给应用集群。 另外，If-Modified-Since也是一个关于缓存的。也就是说，如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回“304 Not Modified”的响应，那客户端就不用下载了，也会节省带宽。 到此为止，我们仅仅是拼凑起了 HTTP 请求的报文格式，接下来，浏览器会把它交给下一层传输层。怎么交给传输层呢？其实也无非是用 Socket 这些东西，只不过用的浏览器里，这些程序不需要你自己写，有人已经帮你写好了。





HTTP 请求的发送 

HTTP 协议是基于 TCP 协议的，所以它使用面向连接的方式发送请求，通过 stream 二进制流的方式传给对方。当然，到了 TCP 层，它会把二进制流变成一个的报文段发送给服务器。 在发送给每个报文段的时候，都需要对方有一个回应 ACK，来保证报文可靠地到达了对方。如果没有回应，那么 TCP 这一层会进行重新传输，直到可以到达。同一个包有可能被传了好多次，但是 HTTP 这一层不需要知道这一点，因为是 TCP 这一层在埋头苦干。 TCP 层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到 IP 头里面，交给 IP 层进行传输。 IP 层需要查看目标地址和自己是否是在同一个局域网。如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去即可；如果不在同一个局域网，就需要发送到网关，还要需要发送 ARP 协议，来获取网关的 MAC 地址，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。 网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。 这样路由器一跳一跳终于到达目标的局域网。这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送 ARP，获得这个目标地址的 MAC 地址，将包发出去。 目标的机器发现 MAC 地址符合，就将包收起来；发现 IP 地址符合，根据 IP 头中协议项，知道自己上一层是 TCP 协议，于是解析 TCP 的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。 TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。

阿尔巴尼亚语阿拉伯语阿姆哈拉语阿塞拜疆语爱尔兰语爱沙尼亚语巴斯克语白俄罗斯语保加利亚语冰岛语波兰语波斯尼亚语波斯语布尔语(南非荷兰语)丹麦语德语俄语法语菲律宾语芬兰语弗里西语高棉语格鲁吉亚语古吉拉特语哈萨克语海地克里奥尔语韩语豪萨语荷兰语吉尔吉斯语加利西亚语加泰罗尼亚语检测语言捷克语卡纳达语科西嘉语克罗地亚语库尔德语拉丁语拉脱维亚语老挝语立陶宛语卢森堡语罗马尼亚语马尔加什语马耳他语马拉地语马拉雅拉姆语马来语马其顿语毛利语蒙古语孟加拉语缅甸语苗语南非科萨语南非祖鲁语尼泊尔语挪威语旁遮普语葡萄牙语普什图语齐切瓦语日语瑞典语萨摩亚语塞尔维亚语塞索托语僧伽罗语世界语斯洛伐克语斯洛文尼亚语斯瓦希里语苏格兰盖尔语宿务语索马里语塔吉克语泰卢固语泰米尔语泰语土耳其语威尔士语乌尔都语乌克兰语乌兹别克语西班牙语希伯来语希腊语夏威夷语信德语匈牙利语修纳语亚美尼亚语伊博语意大利语意第绪语印地语印尼巽他语印尼语印尼爪哇语英语约鲁巴语越南语中文



HTTP 返回的构建 HTTP 的返回报文也是有一定格式的。这也是基于 HTTP 1.1 的。

![](https://static001.geekbang.org/resource/image/1c/c1/1c2cfd4326d0dfca652ac8501321fac1.jpg)

状态码会反应 HTTP 请求的结果。“200”意味着大吉大利；而我们最不想见的，就是“404”，也就是“服务端无法响应这个请求”。然后，短语会大概说一下原因。 接下来是返回首部的key value。 这里面，Retry-After表示，告诉客户端应该在多长时间以后再次尝试一下。“503 错误”是说“服务暂时不再和这个值配合使用”。 在返回的头部里面也会有Content-Type，表示返回的是 HTML，还是 JSON。 构造好了返回的 HTTP 报文，接下来就是把这个报文发送出去。还是交给 Socket 去发送，还是交给 TCP 层，让 TCP 层将返回的 HTML，也分成一个个小的段，并且保证每个段都可靠到达。 这些段加上 TCP 头后会交给 IP 层，然后把刚才的发送过程反向走一遍。虽然两次不一定走相同的路径，但是逻辑过程是一样的，一直到达客户端。 客户端发现 MAC 地址符合、IP 地址符合，于是就会交给 TCP 层。根据序列号看是不是自己要的报文段，如果是，则会根据 TCP 头中的端口号，发给相应的进程。这个进程就是浏览器，浏览器作为客户端也在监听某个端口。 当浏览器拿到了 HTTP 的报文。发现返回“200”，一切正常，于是就从正文中将 HTML 拿出来。HTML 是一个标准的网页格式。浏览器只要根据这个格式，展示出一个绚丽多彩的网页。 这就是一个正常的 HTTP 请求和返回的完整过程。



HTTP 2.0

 当然 HTTP 协议也在不断地进化过程中，在 HTTP1.1 基础上便有了 HTTP 2.0。 HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 的头，而且不考虑 pipeline 模式的话，每次的过程总是像上面描述的那样一去一回。这样在实时性、并发性上都存在问题。 为了解决这些问题，HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key value 在两端建立一个索引表，对相同的头只发送索引表中的索引。 另外，HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。 HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有Header 帧，用于传输 Header 内容，并且会开启一个新的流。再就是Data 帧，用来传输正文实体。多个 Data 帧属于同一个流。 通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。

QUIC 协议的“城会玩”





### HTTPS协议

对称加密 假设你和外卖网站约定了一个密钥，你发送请求的时候用这个密钥进行加密，外卖网站用同样的密钥进行解密。这样就算中间的黑客截获了你的请求，但是它没有密钥，还是破解不了。 这看起来很完美，但是中间有个问题，你们两个怎么来约定这个密钥呢？如果这个密钥在互联网上传输，也是很有可能让黑客截获的。黑客一旦截获这个秘钥，它可以佯作不知，静静地等着你们两个交互。这时候你们之间互通的任何消息，它都能截获并且查看，就等你把银行卡账号和密码发出来。 我们在谍战剧里面经常看到这样的场景，就是特工破译的密码会有个密码本，截获无线电台，通过密码本就能将原文破解出来。怎么把密码本给对方呢？只能通过线下传输。 比如，你和外卖网站偷偷约定时间地点，它给你一个纸条，上面写着你们两个的密钥，然后说以后就用这个密钥在互联网上定外卖了。当然你们接头的时候，也会先约定一个口号，什么“天王盖地虎”之类的，口号对上了，才能把纸条给它。但是，“天王盖地虎”同样也是对称加密密钥，同样存在如何把“天王盖地虎”约定成口号的问题。而且在谍战剧中一对一接头可能还可以，在互联网应用中，客户太多，这样是不行的。 

非对称加密 

所以，只要是对称加密，就会永远在这个死循环里出不来，这个时候，就需要非对称加密介入进来。 非对称加密的私钥放在外卖网站这里，不会在互联网上传输，这样就能保证这个秘钥的私密性。但是，对应私钥的公钥，是可以在互联网上随意传播的，只要外卖网站把这个公钥给你，你们就可以愉快地互通了。 比如说你用公钥加密，说“我要定外卖”，黑客在中间就算截获了这个报文，因为它没有私钥也是解不开的，所以这个报文可以顺利到达外卖网站，外卖网站用私钥把这个报文解出来，然后回复，“那给我银行卡和支付密码吧”。 先别太乐观，这里还是有问题的。回复的这句话，是外卖网站拿私钥加密的，互联网上人人都可以把它打开，当然包括黑客。那外卖网站可以拿公钥加密吗？当然不能，因为它自己的私钥只有它自己知道，谁也解不开。 另外，这个过程还有一个问题，黑客也可以模拟发送“我要定外卖”这个过程的，因为它也有外卖网站的公钥。 为了解决这个问题，看来一对公钥私钥是不够的，客户端也需要有自己的公钥和私钥，并且客户端要把自己的公钥，给外卖网站。 这样，客户端给外卖网站发送的时候，用外卖网站的公钥加密。而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。

数字证书 不对称加密也会有同样的问题，如何将不对称加密的公钥给对方呢？一种是放在一个公网的地址上，让对方下载；另一种就是在建立连接的时候，传给对方。 这两种方法有相同的问题，那就是，作为一个普通网民，你怎么鉴别别人给你的公钥是对的。会不会有人冒充外卖网站，发给你一个它的公钥。接下来，你和它所有的互通，看起来都是没有任何问题的。毕竟每个人都可以创建自己的公钥和私钥。



阿尔巴尼亚语阿拉伯语阿姆哈拉语阿塞拜疆语爱尔兰语爱沙尼亚语巴斯克语白俄罗斯语保加利亚语冰岛语波兰语波斯尼亚语波斯语布尔语(南非荷兰语)丹麦语德语俄语法语菲律宾语芬兰语弗里西语高棉语格鲁吉亚语古吉拉特语哈萨克语海地克里奥尔语韩语豪萨语荷兰语吉尔吉斯语加利西亚语加泰罗尼亚语检测语言捷克语卡纳达语科西嘉语克罗地亚语库尔德语拉丁语拉脱维亚语老挝语立陶宛语卢森堡语罗马尼亚语马尔加什语马耳他语马拉地语马拉雅拉姆语马来语马其顿语毛利语蒙古语孟加拉语缅甸语苗语南非科萨语南非祖鲁语尼泊尔语挪威语旁遮普语葡萄牙语普什图语齐切瓦语日语瑞典语萨摩亚语塞尔维亚语塞索托语僧伽罗语世界语斯洛伐克语斯洛文尼亚语斯瓦希里语苏格兰盖尔语宿务语索马里语塔吉克语泰卢固语泰米尔语泰语土耳其语威尔士语乌尔都语乌克兰语乌兹别克语西班牙语希伯来语希腊语夏威夷语信德语匈牙利语修纳语亚美尼亚语伊博语意大利语意第绪语印地语印尼巽他语印尼语印尼爪哇语英语约鲁巴语越南语中文

这个时候就需要权威部门的介入了，就像每个人都可以打印自己的简历，说自己是谁，但是有公安局盖章的，就只有户口本，这个才能证明你是你。这个由权威部门颁发的称为证书（Certificate）。 证书里面有什么呢？当然应该有公钥，这是最重要的；还有证书的所有者，就像户口本上有你的姓名和身份证号，说明这个户口本是你的；另外还有证书的发布机构和证书的有效期，这个有点像身份证上的机构是哪个区公安局，有效期到多少年。 这个证书是怎么生成的呢？会不会有人假冒权威机构颁发证书呢？就像有假身份证、假户口本一样。生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为CA（ Certificate Authority）。 证书请求可以通过这个命令生成。



HTTPS 的工作模式

![](https://static001.geekbang.org/resource/image/70/02/7042f5c3d9e3437d5b0b30b30f43c802.jpg)

**重放与篡改问题**





### 流媒体协议

三个名词系列 我这里列三个名词系列，你先大致有个印象。 

名词系列一：AVI、MPEG、RMVB、MP4、MOV、FLV、WebM、WMV、ASF、MKV。例如 RMVB 和 MP4，看着是不是很熟悉？ 

名词系列二：H.261、 H.262、H.263、H.264、H.265。这个是不是就没怎么听过了？别着急，你先记住，要重点关注 H.264。

 名词系列三：MPEG-1、MPEG-2、MPEG-4、MPEG-7。MPEG 好像听说过，但是后面的数字是怎么回事？是不是又熟悉又陌生？

这里，我想问你个问题，视频是什么？我说，其实就是快速播放一连串连续的图片。 每一张图片，我们称为一帧。只要每秒钟帧的数据足够多，也即播放得足够快。比如每秒 30 帧，以人的眼睛的敏感程度，是看不出这是一张张独立的图片的，这就是我们常说的帧率（FPS）。 每一张图片，都是由像素组成的，假设为 1024*768（这个像素数不算多）。每个像素由 RGB 组成，每个 8 位，共 24 位。 我们来算一下，每秒钟的视频有多大？ 30 帧 × 1024 × 768 × 24 = 566,231,040Bits = 70,778,880Bytes 如果一分钟呢？4,246,732,800Bytes，已经是 4 个 G 了。 是不是不算不知道，一算吓一跳？这个数据量实在是太大，根本没办法存储和传输。如果这样存储，你的硬盘很快就满了；如果这样传输，那多少带宽也不够用啊！ 怎么办呢？人们想到了编码，就是看如何用尽量少的 Bit 数保存视频，使播放的时候画面看起来仍然很精美。编码是一个压缩的过程。



视频和图片的压缩过程有什么特点？ 

之所以能够对视频流中的图片进行压缩，因为视频和图片有这样一些特点。

 空间冗余：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整地保存，可以隔几个保存一个，中间的用算法计算出来。

 时间冗余：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。

视觉冗余：人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。 

编码冗余：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似霍夫曼编码（Huffman Coding）的思路。

![](https://static001.geekbang.org/resource/image/43/b4/433a51e15d0ed50e313454ceccd61cb4.jpg)

视频编码的两大流派 能不能形成一定的标准呢？要不然开发视频播放的人得累死了。当然能，我这里就给你介绍，视频编码的两大流派。 流派一：ITU（International Telecommunications Union）的 VCEG（Video Coding Experts Group），这个称为国际电联下的 VCEG。既然是电信，可想而知，他们最初做视频编码，主要侧重传输。名词系列二，就是这个组织制定的标准。 流派二：ISO（International Standards Organization）的 MPEG（Moving Picture Experts Group），这个是ISO 旗下的 MPEG，本来是做视频存储的。例如，编码后保存在 VCD 和 DVD 中。当然后来也慢慢侧重视频传输了。名词系列三，就是这个组织制定的标准。 后来，ITU-T（国际电信联盟电信标准化部门，ITU Telecommunication Standardization Sector）与 MPEG 联合制定了 H.264/MPEG-4 AVC，这才是我们这一节要重点关注的。 经过编码之后，生动活泼的一帧一帧的图像，就变成了一串串让人看不懂的二进制，这个二进制可以放在一个文件里面，按照一定的格式保存起来，这就是名词系列一。 其实这些就是视频保存成文件的格式。例如，前几个字节是什么意义，后几个字节是什么意义，然后是数据，数据中保存的就是编码好的结果。



如何在直播里看到帅哥美女？

![](https://static001.geekbang.org/resource/image/e4/f8/e4d4b538c434ec0eade37028a34391f8.jpg)

编码：如何将丰富多彩的图片变成二进制流？

一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列。

拉流：观众的客户端如何看到视频？



### P2P协议

如果你想下载一个电影，一般会通过什么方式呢？ 当然，最简单的方式就是通过HTTP进行下载。但是相信你有过这样的体验，通过浏览器下载的时候，只要文件稍微大点，下载的速度就奇慢无比。 还有种下载文件的方式，就是通过FTP，也即文件传输协议。FTP 采用两个 TCP 连接来传输一个文件。 控制连接：服务器以被动的方式，打开众所周知用于 FTP 的端口 21，客户端则主动发起连接。该连接将命令从客户端传给服务器，并传回服务器的应答。常用的命令有：list——获取文件目录；reter——取一个文件；store——存一个文件。 数据连接：每当一个文件在客户端与服务器之间传输时，就创建一个数据连接。



FTP 的两种工作模式 每传输一个文件，都要建立一个全新的数据连接。FTP 有两种工作模式，分别是主动模式（PORT）和被动模式（PASV），这些都是站在 FTP 服务器的角度来说的。 主动模式下，客户端随机打开一个大于 1024 的端口 N，向服务器的命令端口 21 发起连接，同时开放 N+1 端口监听，并向服务器发出 “port N+1” 命令，由服务器从自己的数据端口 20，主动连接到客户端指定的数据端口 N+1。 被动模式下，当开启一个 FTP 连接时，客户端打开两个任意的本地端口 N（大于 1024）和 N+1。第一个端口连接服务器的 21 端口，提交 PASV 命令。然后，服务器会开启一个任意的端口 P（大于 1024），返回“227 entering passive mode”消息，里面有 FTP 服务器开放的用来进行数据传输的端口。客户端收到消息取得端口号之后，会通过 N+1 号端口连接服务器的端口 P，然后在两个端口之间进行数据传输。



P2P 是什么？ 但是无论是 HTTP 的方式，还是 FTP 的方式，都有一个比较大的缺点，就是难以解决单一服务器的带宽压力， 因为它们使用的都是传统的客户端服务器的方式。 后来，一种创新的、称为 P2P 的方式流行起来。P2P就是peer-to-peer。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。这些设备我们姑且称为 peer。 想要下载一个文件的时候，你只要得到那些已经存在了文件的 peer，并和这些 peer 之间，建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。一旦下载了文件，你也就成为 peer 中的一员，你旁边的那些机器，也可能会选择从你这里下载文件，所以当你使用 P2P 软件的时候，例如 BitTorrent，往往能够看到，既有下载流量，也有上传的流量，也即你自己也加入了这个 P2P 的网络，自己从别人那里下载，同时也提供给其他人下载。可以想象，这种方式，参与的人越多，下载速度越快，一切完美。



种子（.torrent）文件 但是有一个问题，当你想下载一个文件的时候，怎么知道哪些 peer 有这个文件呢？ 这就用到种子啦，也即咱们比较熟悉的.torrent 文件。.torrent 文件由两部分组成，分别是：announce（tracker URL）和文件信息。 文件信息里面有这些内容。 info 区：这里指定的是该种子有几个文件、文件有多长、目录结构，以及目录和文件的名字。 Name 字段：指定顶层目录名字。 每个段的大小：BitTorrent（简称 BT）协议把一个文件分成很多个小段，然后分段下载。 段哈希值：将整个种子中，每个段的 SHA-1 哈希值拼在一起。 下载时，BT 客户端首先解析.torrent 文件，得到 tracker 地址，然后连接 tracker 服务器。tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。下载者再连接其他下载者，根据.torrent 文件，两者分别对方告知自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，并分散了单个线路上的数据流量，因此减轻了服务器的负担。

下载者每得到一个块，需要算出下载块的 Hash 验证码，并与.torrent 文件中的对比。如果一样，则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容的准确性问题。 从这个过程也可以看出，这种方式特别依赖 tracker。tracker 需要收集下载者信息的服务器，并将此信息提供给其他下载者，使下载者们相互连接起来，传输数据。虽然下载的过程是非中心化的，但是加入这个 P2P 网络的时候，都需要借助 tracker 中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源。 所以，这种工作方式有一个弊端，一旦 tracker 服务器出现故障或者线路遭到屏蔽，BT 工具就无法正常工作了





去中心化网络（DHT） 那能不能彻底非中心化呢？ 于是，后来就有了一种叫作DHT（Distributed Hash Table）的去中心化网络。每个加入这个 DHT 网络的人，都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。 有一种著名的 DHT 协议，叫Kademlia 协议。这个和区块链的概念一样，很抽象，我来详细讲一下这个协议。 任何一个 BitTorrent 启动之后，它都有两个角色。一个是peer，监听一个 TCP 端口，用来上传和下载文件，这个角色表明，我这里有某个文件。另一个角色DHT node，监听一个 UDP 的端口，通过这个角色，这个节点加入了一个 DHT 的网络。 

哈希值 当然，每个 DHT node 不会有全局的知识，也即不知道所有的文件保存在哪里，它只需要知道一部分。那应该知道哪一部分呢？这就需要用哈希算法计算出来。 每个文件可以计算出一个哈希值，而DHT node 的 ID 是和哈希值相同长度的串。 DHT 算法是这样规定的：如果一个文件计算出一个哈希值，则和这个哈希值一样的那个 DHT node，就有责任知道从哪里下载这个文件，即便它自己没保存这个文件。 当然不一定这么巧，总能找到和哈希值一模一样的，有可能一模一样的 DHT node 也下线了，所以 DHT 算法还规定：除了一模一样的那个 DHT node 应该知道，ID 和这个哈希值非常接近的 N 个 DHT node 也应该知道。 什么叫和哈希值接近呢？例如只修改了最后一位，就很接近；修改了倒数 2 位，也不远；修改了倒数 3 位，也可以接受。总之，凑齐了规定的 N 这个数就行。 刚才那个图里，文件 1 通过哈希运算，得到匹配 ID 的 DHT node 为 node C，当然还会有其他的，我这里没有画出来。所以，node C 有责任知道文件 1 的存放地址，虽然 node C 本身没有存放文件 1。 同理，文件 2 通过哈希运算，得到匹配 ID 的 DHT node 为 node E，但是 node D 和 E 的 ID 值很近，所以 node D 也知道。当然，文件 2 本身没有必要一定在 node D 和 E 里，但是碰巧这里就在 E 那有一份。 接下来一个新的节点 node new 上线了。如果想下载文件 1，它首先要加入 DHT 网络，如何加入呢？ 在这种模式下，种子.torrent 文件里面就不再是 tracker 的地址了，而是一个 list 的 node 的地址，而所有这些 node 都是已经在 DHT 网络里面的。当然随着时间的推移，很可能有退出的，有下线的，但是我们假设，不会所有的都联系不上，总有一个能联系上。 node new 只要在种子里面找到一个 DHT node，就加入了网络。 node new 会计算文件 1 的哈希值，并根据这个哈希值了解到，和这个哈希值匹配，或者很接近的 node 上知道如何下载这个文件，例如计算出来的哈希值就是 node C。 但是 node new 不知道怎么联系上 node C，因为种子里面的 node 列表里面很可能没有 node C，但是它可以问，DHT 网络特别像一个社交网络，node new 只有去它能联系上的 node 问，你们知道不知道 node C 的联系方式呀？ 在 DHT 网络中，每个 node 都保存了一定的联系方式，但是肯定没有 node 的所有联系方式。DHT 网络中，节点之间通过互相通信，也会交流联系方式，也会删除联系方式。和人们的方式一样，你有你的朋友圈，你的朋友有它的朋友圈，你们互相加微信，就互相认识了，过一段时间不联系，就删除朋友关系。 有个理论是，社交网络中，任何两个人直接的距离不超过六度，也即你想联系比尔盖茨，也就六个人就能够联系到了。 所以，node new 想联系 node C，就去万能的朋友圈去问，并且求转发，朋友再问朋友，很快就能找到。如果找不到 C，也能找到和 C 的 ID 很像的节点，它们也知道如何下载文件 1。 在 node C 上，告诉 node new，下载文件 1，要去 B、D、 F，于是 node new 选择和 node B 进行 peer 连接，开始下载，它一旦开始下载，自己本地也有文件 1 了，于是 node new 告诉 node C 以及和 node C 的 ID 很像的那些节点，我也有文件 1 了，可以加入那个文件拥有者列表了。 但是你会发现 node new 上没有文件索引，但是根据哈希算法，一定会有某些文件的哈希值是和 node new 的 ID 匹配上的。在 DHT 网络中，会有节点告诉它，你既然加入了咱们这个网络，你也有责任知道某些文件的下载地址。 好了，一切都分布式了。 这里面遗留几个细节的问题。 DHT node ID 以及文件哈希是个什么东西？ 节点 ID 是一个随机选择的 160bits（20 字节）空间，文件的哈希也使用这样的 160bits 空间。 所谓 ID 相似，具体到什么程度算相似？ 在 Kademlia 网络中，距离是通过异或（XOR）计算的。我们就不以 160bits 举例了。我们以 5 位来举例。 01010 与 01000 的距离，就是两个 ID 之间的异或值，为 00010，也即为 2。 01010 与 00010 的距离为 01000，也即为 8,。01010 与 00011 的距离为 01001，也即 8+1=9 。以此类推，高位不同的，表示距离更远一些；低位不同的，表示距离更近一些，总的距离为所有的不同的位的距离之和。 这个距离不能比喻为地理位置，因为在 Kademlia 网络中，位置近不算近，ID 近才算近，所以我把这个距离比喻为社交距离，也即在朋友圈中的距离，或者社交网络中的距离。这个和你住的位置没有关系，和人的经历关系比较大。 还是以 5 位 ID 来举例，就像在领英中，排第一位的表示最近一份工作在哪里，第二位的表示上一份工作在哪里，然后第三位的是上上份工作，第四位的是研究生在哪里读，第五位的表示大学在哪里读。 如果你是一个猎头，在上面找候选人，当然最近的那份工作是最重要的。而对于工作经历越丰富的候选人，大学在哪里读的反而越不重要。 

DHT 网络中的朋友圈是怎么维护的？ 就像人一样，虽然我们常联系人的只有少数，但是朋友圈里肯定是远近都有。DHT 网络的朋友圈也是一样，远近都有，并且按距离分层。 假设某个节点的 ID 为 01010，如果一个节点的 ID，前面所有位数都与它相同，只有最后 1 位不同。这样的节点只有 1 个，为 01011。与基础节点的异或值为 00001，即距离为 1；对于 01010 而言，这样的节点归为“k-bucket 1”。 如果一个节点的 ID，前面所有位数都相同，从倒数第 2 位开始不同，这样的节点只有 2 个，即 01000 和 01001，与基础节点的异或值为 00010 和 00011，即距离范围为 2 和 3；对于 01010 而言，这样的节点归为“k-bucket 2”。 如果一个节点的 ID，前面所有位数相同，从倒数第 i 位开始不同，这样的节点只有 2^(i-1) 个，与基础节点的距离范围为 [2^(i-1), 2^i)；对于 01010 而言，这样的节点归为“k-bucket i”。 最终到从倒数 160 位就开始都不同。 你会发现，差距越大，陌生人越多，但是朋友圈不能都放下，所以每一层都只放 K 个，这是参数可以配置。



DHT 网络是如何查找朋友的？ 假设，node A 的 ID 为 00110，要找 node B ID 为 10000，异或距离为 10110，距离范围在 [2^4, 2^5)，所以这个目标节点可能在“k-bucket 5”中，这就说明 B 的 ID 与 A 的 ID 从第 5 位开始不同，所以 B 可能在“k-bucket 5”中。 然后，A 看看自己的 k-bucket 5 有没有 B。如果有，太好了，找到你了；如果没有，在 k-bucket 5 里随便找一个 C。因为是二进制，C、B 都和 A 的第 5 位不同，那么 C 的 ID 第 5 位肯定与 B 相同，即它与 B 的距离会小于 2^4，相当于比 A、B 之间的距离缩短了一半以上。 再请求 C，在它自己的通讯录里，按同样的查找方式找一下 B。如果 C 知道 B，就告诉 A；如果 C 也不知道 B，那 C 按同样的搜索方法，可以在自己的通讯录里找到一个离 B 更近的 D 朋友（D、B 之间距离小于 2^3），把 D 推荐给 A，A 请求 D 进行下一步查找。 Kademlia 的这种查询机制，是通过折半查找的方式来收缩范围，对于总的节点数目为 N，最多只需要查询 log2(N) 次，就能够找到。 例如，图中这个最差的情况。 A 和 B 每一位都不一样，所以相差 31，A 找到的朋友 C，不巧正好在中间。和 A 的距离是 16，和 B 距离为 15，于是 C 去自己朋友圈找的时候，不巧找到 D，正好又在中间，距离 C 为 8，距离 B 为 7。于是 D 去自己朋友圈找的时候，不巧找到 E，正好又在中间，距离 D 为 4，距离 B 为 3，E 在朋友圈找到 F，距离 E 为 2，距离 B 为 1，最终在 F 的朋友圈距离 1 的地方找到 B。当然这是最最不巧的情况，每次找到的朋友都不远不近，正好在中间。 如果碰巧了，在 A 的朋友圈里面有 G，距离 B 只有 3，然后在 G 的朋友圈里面一下子就找到了 B，两次就找到了。 在 DHT 网络中，朋友之间怎么沟通呢？ Kademlia 算法中，每个节点只有 4 个指令。 PING：测试一个节点是否在线，还活着没，相当于打个电话，看还能打通不。 STORE：要求一个节点存储一份数据，既然加入了组织，有义务保存一份数据。 FIND_NODE：根据节点 ID 查找一个节点，就是给一个 160 位的 ID，通过上面朋友圈的方式找到那个节点。 FIND_VALUE：根据 KEY 查找一个数据，实则上跟 FIND_NODE 非常类似。KEY 就是文件对应的 160 位的 ID，就是要找到保存了文件的节点。 DHT 网络中，朋友圈如何更新呢？ 每个 bucket 里的节点，都按最后一次接触的时间倒序排列，这就相当于，朋友圈里面最近联系过的人往往是最熟的。 每次执行四个指令中的任意一个都会触发更新。 当一个节点与自己接触时，检查它是否已经在 k-bucket 中，也就是说是否已经在朋友圈。如果在，那么将它挪到 k-bucket 列表的最底，也就是最新的位置，刚联系过，就置顶一下，方便以后多联系；如果不在，新的联系人要不要加到通讯录里面呢？假设通讯录已满的情况，PING 一下列表最上面，也即最旧的一个节点。如果 PING 通了，将旧节点挪到列表最底，并丢弃新节点，老朋友还是留一下；如果 PING 不通，删除旧节点，并将新节点加入列表，这人联系不上了，删了吧。 这个机制保证了任意节点加入和离开都不影响整体网络。



### DNS协议

DNS 服务器 在网络世界，也是这样的。你肯定记得住网站的名称，但是很难记住网站的 IP 地址，因而也需要一个地址簿，就是DNS 服务器。 由此可见，DNS 在日常生活中多么重要。每个人上网，都需要访问它，但是同时，这对它来讲也是非常大的挑战。一旦它出了故障，整个互联网都将瘫痪。另外，上网的人分布在全世界各地，如果大家都去同一个地方访问某一台服务器，时延将会非常大。因而，DNS 服务器，一定要设置成高可用、高并发和分布式的。 于是，就有了这样树状的层次结构。

![](https://static001.geekbang.org/resource/image/59/a6/59f79cba26904ff721aabfcdc0c27da6.jpg)根 DNS 服务器 ：返回顶级域 DNS 服务器的 IP 地址 顶级域 DNS 服务器：返回权威 DNS 服务器的 IP 地址 权威 DNS 服务器 ：返回相应主机的 IP 地址





DNS 解析流程 为了提高 DNS 的解析性能，很多网络都会就近部署 DNS 缓存服务器。于是，就有了以下的 DNS 解析流程。 电脑客户端会发出一个 DNS 请求，问 www.163.com 的 IP 是啥啊，并发给本地域名服务器 (本地 DNS)。那本地域名服务器 (本地 DNS) 是什么呢？如果是通过 DHCP 配置，本地 DNS 由你的网络服务商（ISP），如电信、移动等自动分配，它通常就在你网络服务商的某个机房。 本地 DNS 收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应 IP 地址的大表格。如果能找到 www.163.com，它直接就返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大，能告诉我 www.163.com 的 IP 地址吗？”根域名服务器是最高层次的，全球共有 13 套。它不直接用于域名解析，但能指明一条道路。 根 DNS 收到来自本地 DNS 的请求，发现后缀是 .com，说：“哦，www.163.com 啊，这个域名是由.com 区域管理，我给你它的顶级域名服务器的地址，你去问问它吧。” 本地 DNS 转向问顶级域名服务器：“老二，你能告诉我 www.163.com 的 IP 地址吗？”顶级域名服务器就是大名鼎鼎的比如 .com、.net、 .org 这些一级域名，它负责管理二级域名，比如 163.com，所以它能提供一条更清晰的方向。 顶级域名服务器说：“我给你负责 www.163.com 区域的权威 DNS 服务器的地址，你去问它应该能问到。” 本地 DNS 转向问权威 DNS 服务器：“您好，www.163.com 对应的 IP 是啥呀？”163.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。 权限 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。 至此，我们完成了 DNS 的解析过程。现在总结一下，整个过程我画成了一个图。 





![](https://static001.geekbang.org/resource/image/ff/f2/ff7e8f824ebd1f7e16ef5d70cd79bdf2.jpg)

负载均衡 站在客户端角度，这是一次DNS 递归查询过程。因为本地 DNS 全权为它效劳，它只要坐等结果即可。在这个过程中，DNS 除了可以通过名称映射为 IP 地址，它还可以做另外一件事，就是负载均衡。 还是以访问“外婆家”为例，还是我们开头的“外婆家”，但是，它可能有很多地址，因为它在杭州可以有很多家。所以，如果一个人想去吃“外婆家”，他可以就近找一家店，而不用大家都去同一家，这就是负载均衡。 DNS 首先可以做内部负载均衡。 例如，一个应用要访问数据库，在这个应用里面应该配置这个数据库的 IP 地址，还是应该配置这个数据库的域名呢？显然应该配置域名，因为一旦这个数据库，因为某种原因，换到了另外一台机器上，而如果有多个应用都配置了这台数据库的话，一换 IP 地址，就需要将这些应用全部修改一遍。但是如果配置了域名，则只要在 DNS 服务器里，将域名映射为新的 IP 地址，这个工作就完成了，大大简化了运维。 在这个基础上，我们可以再进一步。例如，某个应用要访问另外一个应用，如果配置另外一个应用的 IP 地址，那么这个访问就是一对一的。但是当被访问的应用撑不住的时候，我们其实可以部署多个。但是，访问它的应用，如何在多个之间进行负载均衡？只要配置成为域名就可以了。在域名解析的时候，我们只要配置策略，这次返回第一个 IP，下次返回第二个 IP，就可以实现负载均衡了。 另外一个更加重要的是，DNS 还可以做全局负载均衡。 为了保证我们的应用高可用，往往会部署在多个机房，每个地方都会有自己的 IP 地址。当用户访问某个域名的时候，这个 IP 地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要在 DNS 服务器里面，将这个数据中心对应的 IP 地址删除，就可以实现一定的高可用。 另外，我们肯定希望北京的用户访问北京的数据中心，上海的用户访问上海的数据中心，这样，客户体验就会非常好，访问速度就会超快。这就是全局负载均衡的概念。



示例：DNS 访问数据中心中对象存储上的静态资源 我们通过 DNS 访问数据中心中对象存储上的静态资源为例，看一看整个过程。 假设全国有多个数据中心，托管在多个运营商，每个数据中心三个可用区（Available Zone）。对象存储通过跨可用区部署，实现高可用性。在每个数据中心中，都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器（Proxy-server）。 

![](https://static001.geekbang.org/resource/image/56/d1/569ddad1a0c5a5f60341fbe023b47cd1.jpg)

当一个客户端要访问 object.yourcompany.com 的时候，需要将域名转换为 IP 地址进行访问，所以它要请求本地 DNS 解析器。 本地 DNS 解析器先查看看本地的缓存是否有这个记录。如果有则直接使用，因为上面的过程太复杂了，如果每次都要递归解析，就太麻烦了。 如果本地无缓存，则需要请求本地的 DNS 服务器。 本地的 DNS 服务器一般部署在你的数据中心或者你所在的运营商的网络中，本地 DNS 服务器也需要看本地是否有缓存，如果有则返回，因为它也不想把上面的递归过程再走一遍。 至 7. 如果本地没有，本地 DNS 才需要递归地从根 DNS 服务器，查到.com 的顶级域名服务器，最终查到 yourcompany.com 的权威 DNS 服务器，给本地 DNS 服务器，权威 DNS 服务器按说会返回真实要访问的 IP 地址。 对于不需要做全局负载均衡的简单应用来讲，yourcompany.com 的权威 DNS 服务器可以直接将 object.yourcompany.com 这个域名解析为一个或者多个 IP 地址，然后客户端可以通过多个 IP 地址，进行简单的轮询，实现简单的负载均衡。 但是对于复杂的应用，尤其是跨地域跨运营商的大型应用，则需要更加复杂的全局负载均衡机制，因而需要专门的设备或者服务器来做这件事情，这就是全局负载均衡器（GSLB，Global Server Load Balance）。 在 yourcompany.com 的 DNS 服务器中，一般是通过配置 CNAME 的方式，给 object.yourcompany.com 起一个别名，例如 object.vip.yourcomany.com，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。 图中画了两层的 GSLB，是因为分运营商和地域。我们希望不同运营商的客户，可以访问相同运营商机房中的资源，这样不跨运营商访问，有利于提高吞吐量，减少时延。 第一层 GSLB，通过查看请求它的本地 DNS 服务器所在的运营商，就知道用户所在的运营商。假设是移动，通过 CNAME 的方式，通过另一个别名 object.yd.yourcompany.com，告诉本地 DNS 服务器去请求第二层的 GSLB。 第二层 GSLB，通过查看请求它的本地 DNS 服务器所在的地址，就知道用户所在的地理位置，然后将距离用户位置比较近的 Region 里面，六个内部负载均衡（SLB，Server Load Balancer）的地址，返回给本地 DNS 服务器。 本地 DNS 服务器将结果返回给本地 DNS 解析器。 本地 DNS 解析器将结果缓存后，返回给客户端。 客户端开始访问属于相同运营商的距离较近的 Region 1 中的对象存储，当然客户端得到了六个 IP 地址，它可以通过负载均衡的方式，随机或者轮询选择一个可用区进行访问。对象存储一般会有三个备份，从而可以实现对存储读写的负载均衡。



### HTTPDNS

传统 DNS 存在哪些问题？

1. 域名缓存问题
   它可以在本地做一个缓存，也就是说，不是每一个请求，它都会去访问权威 DNS 服务器，而是访问过一次就把结果缓存到自己本地，当其他人来问的时候，直接就返回这个缓存数据。 这就相当于导游去过一个饭店，自己脑子记住了地址，当有一个游客问的时候，他就凭记忆回答了，不用再去查地址簿。这样经常存在的一个问题是，人家那个饭店明明都已经搬了，结果作为导游，他并没有刷新这个缓存，结果你辛辛苦苦到了这个地点，发现饭店已经变成了服装店，你是不是会非常失望？ 另外，有的运营商会把一些静态页面，缓存到本运营商的服务器内，这样用户请求的时候，就不用跨运营商进行访问，这样既加快了速度，也减少了运营商之间流量计算的成本。在域名解析的时候，不会将用户导向真正的网站，而是指向这个缓存的服务器。 很多情况下是看不出问题的，但是当页面更新，用户会访问到老的页面，问题就出来了。例如，你听说一个餐馆推出了一个新菜，你想去尝一下。结果导游告诉你，在这里吃也是一样的。有的游客会觉得没问题，但是对于想尝试新菜的人来说，如果导游说带你去，但其实并没有吃到新菜，你是不是也会非常失望呢？ 再就是本地的缓存，往往使得全局负载均衡失败，因为上次进行缓存的时候，缓存中的地址不一定是这次访问离客户最近的地方，如果把这个地址返回给客户，那肯定就会绕远路。 就像上一次客户要吃西湖醋鱼的事，导游知道西湖边有一家，因为当时游客就在西湖边，可是，下一次客户在灵隐寺，想吃西湖醋鱼的时候，导游还指向西湖边的那一家，那这就绕的太远了



2. 域名转发问题 缓存问题还是说本地域名解析服务，还是会去权威 DNS 服务器中查找，只不过不是每次都要查找。可以说这还是大导游、大中介。还有一些小导游、小中介，有了请求之后，直接转发给其他运营商去做解析，自己只是外包了出去。 这样的问题是，如果是 A 运营商的客户，访问自己运营商的 DNS 服务器，如果 A 运营商去权威 DNS 服务器查询的话，权威 DNS 服务器知道你是 A 运营商的，就返回给一个部署在 A 运营商的网站地址，这样针对相同运营商的访问，速度就会快很多。 但是 A 运营商偷懒，将解析的请求转发给 B 运营商，B 运营商去权威 DNS 服务器查询的话，权威服务器会误认为，你是 B 运营商的，那就返回给你一个在 B 运营商的网站地址吧，结果客户的每次访问都要跨运营商，速度就会很慢。

3. 出口 NAT 问题 前面讲述网关的时候，我们知道，出口的时候，很多机房都会配置NAT，也即网络地址转换，使得从这个网关出去的包，都换成新的 IP 地址，当然请求返回的时候，在这个网关，再将 IP 地址转换回去，所以对于访问来说是没有任何问题。 但是一旦做了网络地址的转换，权威的 DNS 服务器，就没办法通过这个地址，来判断客户到底是来自哪个运营商，而且极有可能因为转换过后的地址，误判运营商，导致跨运营商的访问。
4.   域名更新问题 本地 DNS 服务器是由不同地区、不同运营商独立部署的。对域名解析缓存的处理上，实现策略也有区别，有的会偷懒，忽略域名解析结果的 TTL 时间限制，在权威 DNS 服务器解析变更的时候，解析结果在全网生效的周期非常漫长。但是有的时候，在 DNS 的切换中，场景对生效时间要求比较高。 例如双机房部署的时候，跨机房的负载均衡和容灾多使用 DNS 来做。当一个机房出问题之后，需要修改权威 DNS，将域名指向新的 IP 地址，但是如果更新太慢，那很多用户都会出现访问异常。 这就像，有的导游比较勤快、敬业，时时刻刻关注酒店、餐馆、交通的变化，问他的时候，往往会得到最新情况。有的导游懒一些，8 年前背的导游词就没换过，问他的时候，指的路往往就是错的。 5. 解析延迟问题 从上一节的 DNS 查询过程来看，DNS 的查询过程需要递归遍历多个 DNS 服务器，才能获得最终的解析结果，这会带来一定的时延，甚至会解析超时。 





HTTPDNS 的工作模式 既然 DNS 解析中有这么多问题，那怎么办呢？难不成退回到直接用 IP 地址？这样显然不合适，所以就有了HTTPDNS。 HTTPNDS 其实就是，不走传统的 DNS 解析，而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个运营商。当客户端需要 DNS 解析的时候，直接通过 HTTP 协议进行请求这个服务器集群，得到就近的地址。 这就相当于每家基于 HTTP 协议，自己实现自己的域名解析，自己做一个自己的地址簿，而不使用统一的地址簿。但是默认的域名解析都是走 DNS 的，因而使用 HTTPDNS 需要绕过默认的 DNS 路径，就不能使用默认的客户端。使用 HTTPDNS 的，往往是手机应用，需要在手机端嵌入支持 HTTPDNS 的客户端 SDK。 通过自己的 HTTPDNS 服务器和自己的 SDK，实现了从依赖本地导游，到自己上网查询做旅游攻略，进行自由行，爱怎么玩怎么玩。这样就能够避免依赖导游，而导游又不专业，你还不能把他怎么样的尴尬。 下面我来解析一下HTTPDNS 的工作模式。 在客户端的 SDK 里动态请求服务端，获取 HTTPDNS 服务器的 IP 列表，缓存到本地。随着不断地解析域名，SDK 也会在本地缓存 DNS 域名解析的结果。 当手机应用要访问一个地址的时候，首先看是否有本地的缓存，如果有就直接返回。这个缓存和本地 DNS 的缓存不一样的是，这个是手机应用自己做的，而非整个运营商统一做的。如何更新、何时更新，手机应用的客户端可以和服务器协调来做这件事情。 如果本地没有，就需要请求 HTTPDNS 的服务器，在本地 HTTPDNS 服务器的 IP 列表中，选择一个发出 HTTP 的请求，会返回一个要访问的网站的 IP 列表。 请求的方式是这样的。 curl http://106.2.xxx.xxx/d?dn=c.m.163.com {"dns":[{"host":"c.m.163.com","ips":["223.252.199.12"],"ttl":300,"http2":0}],"client":{"ip":"106.2.81.50","line":269692944}} 复制代码 手机客户端自然知道手机在哪个运营商、哪个地址。由于是直接的 HTTP 通信，HTTPDNS 服务器能够准确知道这些信息，因而可以做精准的全局负载均衡。

![](https://static001.geekbang.org/resource/image/91/00/914d44e3d9246804b1b670b216146100.jpg)

当然，当所有这些都不工作的时候，可以切换到传统的 LocalDNS 来解析，慢也比访问不到好。那 HTTPDNS 是如何解决上面的问题的呢？ 其实归结起来就是两大问题。一是解析速度和更新速度的平衡问题，二是智能调度的问题，对应的解决方案是 HTTPDNS 的缓存设计和调度设计。



HTTPDNS 的缓存设计 解析 DNS 过程复杂，通信次数多，对解析速度造成很大影响。为了加快解析，因而有了缓存，但是这又会产生缓存更新速度不及时的问题。最要命的是，这两个方面都掌握在别人手中，也即本地 DNS 服务器手中，它不会为你定制，你作为客户端干着急没办法。 而 HTTPDNS 就是将解析速度和更新速度全部掌控在自己手中。一方面，解析的过程，不需要本地 DNS 服务递归的调用一大圈，一个 HTTP 的请求直接搞定，要实时更新的时候，马上就能起作用；另一方面为了提高解析速度，本地也有缓存，缓存是在客户端 SDK 维护的，过期时间、更新时间，都可以自己控制。 HTTPDNS 的缓存设计策略也是咱们做应用架构中常用的缓存设计模式，也即分为客户端、缓存、数据源三层。 对于应用架构来讲，就是应用、缓存、数据库。常见的是 Tomcat、Redis、MySQL。 对于 HTTPDNS 来讲，就是手机客户端、DNS 缓存、HTTPDNS 服务器。



只要是缓存模式，就存在缓存的过期、更新、不一致的问题，解决思路也是很像的。 例如 DNS 缓存在内存中，也可以持久化到存储上，从而 APP 重启之后，能够尽快从存储中加载上次累积的经常访问的网站的解析结果，就不需要每次都全部解析一遍，再变成缓存。这有点像 Redis 是基于内存的缓存，但是同样提供持久化的能力，使得重启或者主备切换的时候，数据不会完全丢失。 SDK 中的缓存会严格按照缓存过期时间，如果缓存没有命中，或者已经过期，而且客户端不允许使用过期的记录，则会发起一次解析，保障记录是更新的。 解析可以同步进行，也就是直接调用 HTTPDNS 的接口，返回最新的记录，更新缓存；也可以异步进行，添加一个解析任务到后台，由后台任务调用 HTTPDNS 的接口。 同步更新的优点是实时性好，缺点是如果有多个请求都发现过期的时候，同时会请求 HTTPDNS 多次，其实是一种浪费。 同步更新的方式对应到应用架构中缓存的Cache-Aside 机制，也即先读缓存，不命中读数据库，同时将结果写入缓存。



HTTPDNS 的调度设计 由于客户端嵌入了 SDK，因而就不会因为本地 DNS 的各种缓存、转发、NAT，让权威 DNS 服务器误会客户端所在的位置和运营商，而可以拿到第一手资料。 在客户端，可以知道手机是哪个国家、哪个运营商、哪个省，甚至哪个市，HTTPDNS 服务端可以根据这些信息，选择最佳的服务节点返回。 如果有多个节点，还会考虑错误率、请求时间、服务器压力、网络状况等，进行综合选择，而非仅仅考虑地理位置。当有一个节点宕机或者性能下降的时候，可以尽快进行切换。 要做到这一点，需要客户端使用 HTTPDNS 返回的 IP 访问业务应用。客户端的 SDK 会收集网络请求数据，如错误率、请求时间等网络请求质量数据，并发送到统计后台，进行分析、聚合，以此查看不同的 IP 的服务质量。 在服务端，应用可以通过调用 HTTPDNS 的管理接口，配置不同服务质量的优先级、权重。HTTPDNS 会根据这些策略综合地理位置和线路状况算出一个排序，优先访问当前那些优质的、时延低的 IP 地址。 HTTPDNS 通过智能调度之后返回的结果，也会缓存在客户端。为了不让缓存使得调度失真，客户端可以根据不同的移动网络运营商 WIFI 的 SSID 来分维度缓存。不同的运营商或者 WIFI 解析出来的结果会不同。



### CDN

### 数据中心

### VPN

前面我们讲到了数据中心，里面很复杂，但是有的公司有多个数据中心，需要将多个数据中心连接起来，或者需要办公室和数据中心连接起来。这该怎么办呢？ 第一种方式是走公网，但是公网太不安全，你的隐私可能会被别人偷窥。 第二种方式是租用专线的方式把它们连起来，这是土豪的做法，需要花很多钱。 第三种方式是用 VPN 来连接，这种方法比较折中，安全又不贵

VPN，全名Virtual Private Network，虚拟专用网，就是利用开放的公众网络，建立专用数据传输通道，将远程的分支机构、移动办公人员等连接起来。 VPN 是如何工作的？ VPN 通过隧道技术在公众网络上仿真一条点到点的专线，是通过利用一种协议来传输另外一种协议的技术，这里面涉及三种协议：乘客协议、隧道协议和承载协议。 



知道如何通过自驾进行海南游吗？这其中，你的车怎么通过琼州海峡呢？这里用到轮渡，其实这就用到隧道协议。 在广州这边开车是有“协议”的，例如靠右行驶、红灯停、绿灯行，这个就相当于“被封装”的乘客协议。当然在海南那面，开车也是同样的协议。这就相当于需要连接在一起的一个公司的两个分部。 但是在海上坐船航行，也有它的协议，例如要看灯塔、要按航道航行等。这就是外层的承载协议。 那我的车如何从广州到海南呢？这就需要你遵循开车的协议，将车开上轮渡，所有通过轮渡的车都关在船舱里面，按照既定的规则排列好，这就是隧道协议。 在大海上，你的车是关在船舱里面的，就像在隧道里面一样，这个时候内部的乘客协议，也即驾驶协议没啥用处，只需要船遵从外层的承载协议，到达海南就可以了。 到达之后，外部承载协议的任务就结束了，打开船舱，将车开出来，就相当于取下承载协议和隧道协议的头。接下来，在海南该怎么开车，就怎么开车，还是内部的乘客协议起作用。 在最前面的时候说了，直接使用公网太不安全，所以接下来我们来看一种十分安全的 VPN，IPsec VPN。这是基于 IP 协议的安全隧道协议，为了保证在公网上面信息的安全，因而采取了一定的机制保证安全性。 机制一：私密性，防止信息泄漏给未经授权的个人，通过加密把数据从明文变成无法读懂的密文，从而确保数据的私密性。 前面讲 HTTPS 的时候，说过加密可以分为对称加密和非对称加密。对称加密速度快一些。而 VPN 一旦建立，需要传输大量数据，因而我们采取对称加密。但是同样，对称加密还是存在加密秘钥如何传输的问题，这里需要用到因特网密钥交换（IKE，Internet Key Exchange）协议。 机制二：完整性，数据没有被非法篡改，通过对数据进行 hash 运算，产生类似于指纹的数据摘要，以保证数据的完整性。 机制三：真实性，数据确实是由特定的对端发出，通过身份认证可以保证数据的真实性。 那如何保证对方就是真正的那个人呢？ 第一种方法就是预共享密钥，也就是双方事先商量好一个暗号，比如“天王盖地虎，宝塔镇河妖”，对上了，就说明是对的。 另外一种方法就是用数字签名来验证。咋签名呢？当然是使用私钥进行签名，私钥只有我自己有，所以如果对方能用我的数字证书里面的公钥解开，就说明我是我。 基于以上三个特性，组成了IPsec VPN 的协议簇。这个协议簇内容比较丰富。



### 移动网络

### 云中网络

### 软件定义网络

### 云中的网络安全

### 云中的网络QoS

### 云中网络的隔离GRE、VXLAN

### 容器网络

### 容器网络之Flannel

### 容器网络之Calico

### RPC协议综述

### 基于XML的SOAP协议

### 基于JSON的RESTful接口协议

### 二进制类RPC协议

### 跨语言类RPC协议

### 知识串讲：用双十一的故事串起碎片的网络协议

# 搭建一个网络实验环境